# nanoBERT
A minimal, encoder-only BERT-like Transformer model implemented from scratch in PyTorch, designed for training on the SST-2 sentiment classification dataset from scratch, without pretraining.

## Features

- Encoder-only architecture
- Implemented in PyTorch
- Designed for SST-2 sentiment classification
- No pretraining required

## Installation

Clone the repository then install the required dependencies:

```bash
pip install -r requirements.txt
```

## Usage

Train the model on the SST-2 dataset:

```bash
python train.py
```

## Result

See https://api.wandb.ai/links/pvtien96/zggnon0m

## License

This project is licensed under the MIT License.
